{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6467252-95ac-4072-85b3-a7b83c285e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Selected product @index 1081: JRB 1038 Smallest Mobile Powered By OTG Enabled Android Smart Phone Portable 1038 USB Fan\n",
      "[INFO] Base price used: 249.00\n",
      "[OK] Forecast CSV -> C:\\Users\\sagni\\Downloads\\Price Sense\\price_forecast.csv\n",
      "[OK] Forecast plot -> C:\\Users\\sagni\\Downloads\\Price Sense\\price_forecast.png\n",
      "[OK] Fake-review scores -> C:\\Users\\sagni\\Downloads\\Price Sense\\fake_review_scores.csv\n",
      "[OK] Sentiment pie -> C:\\Users\\sagni\\Downloads\\Price Sense\\sentiment_pie.png\n",
      "\n",
      "=== Prediction Summary ===\n",
      "{\n",
      "  \"product_index\": 1081,\n",
      "  \"product_title\": \"JRB 1038 Smallest Mobile Powered By OTG Enabled Android Smart Phone Portable 1038 USB Fan\",\n",
      "  \"history_points\": 60,\n",
      "  \"forecast_days\": 7,\n",
      "  \"price_forecast_png\": \"C:\\\\Users\\\\sagni\\\\Downloads\\\\Price Sense\\\\price_forecast.png\",\n",
      "  \"price_forecast_csv\": \"C:\\\\Users\\\\sagni\\\\Downloads\\\\Price Sense\\\\price_forecast.csv\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from datetime import date, timedelta\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------- PATHS (Windows-safe raw strings) ----------------------\n",
    "DATA_CSV = r\"C:\\Users\\sagni\\Downloads\\Price Sense\\archive\\flipkart_com-ecommerce_sample.csv\"\n",
    "ARTIFACT_DIR = r\"C:\\Users\\sagni\\Downloads\\Price Sense\"\n",
    "H5_MODEL = Path(ARTIFACT_DIR) / \"price_lstm.h5\"\n",
    "FAKE_REVIEW_PKL = Path(ARTIFACT_DIR) / \"fake_review_lr.pkl\"\n",
    "\n",
    "# Prediction controls (edit as you like)\n",
    "PRODUCT_QUERY = \"phone\"   # substring match over product title (case-insensitive). If None -> use PRODUCT_INDEX.\n",
    "PRODUCT_INDEX = 0         # used if PRODUCT_QUERY finds nothing; picks the Nth product from CSV after filtering\n",
    "FORECAST_DAYS = 7\n",
    "SEED_DAYS = 60            # must match training's synthetic seed_days for similar behavior\n",
    "SEQ_LEN = 7               # must match training's lstm_sequence_len\n",
    "\n",
    "# For reproducibility (synthetic series generation)\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# --- Optional TensorFlow for true LSTM inference (fallback to moving average) ---\n",
    "try:\n",
    "    import tensorflow as tf  # noqa: F401\n",
    "    TF_AVAILABLE = True\n",
    "except Exception:\n",
    "    TF_AVAILABLE = False\n",
    "\n",
    "\n",
    "# -------------------- Data loading / column mapping ---------------------------\n",
    "def load_csv(csv_path: str | Path) -> pd.DataFrame:\n",
    "    p = Path(csv_path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"CSV not found at: {p}\")\n",
    "    try:\n",
    "        return pd.read_csv(p, encoding=\"utf-8\")\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(p, encoding=\"latin1\")\n",
    "\n",
    "\n",
    "def map_columns(df: pd.DataFrame) -> Dict[str, Optional[str]]:\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "\n",
    "    def find(name: str):\n",
    "        for k, v in cols.items():\n",
    "            if name in k:\n",
    "                return v\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        \"title\": find(\"product_name\") or find(\"title\") or list(df.columns)[0],\n",
    "        \"category\": find(\"product_category_tree\") or find(\"category\"),\n",
    "        \"brand\": find(\"brand\"),\n",
    "        \"retail_price\": find(\"retail_price\") or find(\"mrp\") or find(\"price\"),\n",
    "        \"discounted_price\": find(\"discounted_price\") or find(\"discount_price\"),\n",
    "        \"description\": find(\"description\") or find(\"product_description\"),\n",
    "    }\n",
    "\n",
    "\n",
    "# ------------------------ Synthetic price series ------------------------------\n",
    "def synthetic_series(base_price: float,\n",
    "                     days: int,\n",
    "                     noise_frac: float = 0.08,\n",
    "                     deal_prob: float = 0.07,\n",
    "                     deal_frac: float = 0.12) -> np.ndarray:\n",
    "    prices = []\n",
    "    p = float(max(1.0, base_price))\n",
    "    for _ in range(days):\n",
    "        noise = np.random.uniform(-noise_frac, noise_frac) * p\n",
    "        p = max(1.0, p + noise)\n",
    "        if random.random() < deal_prob:\n",
    "            p = max(1.0, p * (1.0 - deal_frac))\n",
    "        prices.append(p)\n",
    "    return np.array(prices, dtype=np.float32)\n",
    "\n",
    "\n",
    "def make_sequences(series: np.ndarray, seq_len: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - seq_len):\n",
    "        X.append(series[i:i + seq_len])\n",
    "        y.append(series[i + seq_len])\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)\n",
    "\n",
    "\n",
    "# --------------------------- Price forecasting --------------------------------\n",
    "def load_lstm_model(h5_path: Path):\n",
    "    if TF_AVAILABLE and h5_path.exists():\n",
    "        try:\n",
    "            return tf.keras.models.load_model(h5_path)\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def forecast_next_k(series: np.ndarray, k: int, seq_len: int, model=None) -> List[float]:\n",
    "    \"\"\"\n",
    "    If a Keras model is available, use it; else moving-average fallback.\n",
    "    \"\"\"\n",
    "    if model is not None:\n",
    "        hist = list(series.astype(np.float32))\n",
    "        scale = max(1e-6, float(np.max(series)))\n",
    "        hist_norm = [v/scale for v in hist]\n",
    "        preds = []\n",
    "        for _ in range(k):\n",
    "            if len(hist_norm) < seq_len:\n",
    "                pad = [hist_norm[0]] * (seq_len - len(hist_norm)) + hist_norm\n",
    "                window = np.array(pad[-seq_len:], dtype=np.float32).reshape(1, seq_len, 1)\n",
    "            else:\n",
    "                window = np.array(hist_norm[-seq_len:], dtype=np.float32).reshape(1, seq_len, 1)\n",
    "            try:\n",
    "                pred_norm = float(model.predict(window, verbose=0)[0, 0])\n",
    "            except Exception:\n",
    "                pred_norm = float(np.mean(hist_norm[-seq_len:]))\n",
    "            pred = float(pred_norm * scale)\n",
    "            preds.append(pred)\n",
    "            hist.append(pred)\n",
    "            hist_norm.append(pred_norm)\n",
    "        return preds\n",
    "\n",
    "    # Fallback: moving average of last seq_len\n",
    "    window = min(seq_len, len(series))\n",
    "    ma = float(np.mean(series[-window:]))\n",
    "    return [ma] * k\n",
    "\n",
    "\n",
    "# ----------------------- Simple sentiment (optional) --------------------------\n",
    "def simple_sentiment_label(t: str) -> str:\n",
    "    tl = (t or \"\").lower()\n",
    "    if any(w in tl for w in [\"bad\", \"poor\", \"worst\", \"awful\"]):\n",
    "        return \"NEGATIVE\"\n",
    "    if any(w in tl for w in [\"good\", \"great\", \"excellent\", \"amazing\", \"love\"]):\n",
    "        return \"POSITIVE\"\n",
    "    return \"NEUTRAL\"\n",
    "\n",
    "\n",
    "# -------------------- Fake review features (match training) -------------------\n",
    "@dataclass\n",
    "class ReviewFeatures:\n",
    "    length: int\n",
    "    exclam: int\n",
    "    caps_ratio: float\n",
    "    unique_ratio: float\n",
    "    digits: int\n",
    "    words: int\n",
    "\n",
    "\n",
    "def featurize(text: str) -> ReviewFeatures:\n",
    "    import re\n",
    "    t = text or \"\"\n",
    "    words = re.findall(r\"[A-Za-z0-9']+\", t)\n",
    "    words_lower = [w.lower() for w in words]\n",
    "    unique_ratio = (len(set(words_lower)) / (len(words_lower) + 1e-6))\n",
    "    caps_ratio = (sum(1 for c in t if c.isupper()) / (len(t) + 1e-6))\n",
    "    digits = sum(ch.isdigit() for ch in t)\n",
    "    return ReviewFeatures(\n",
    "        length=len(t),\n",
    "        exclam=t.count(\"!\"),\n",
    "        caps_ratio=float(caps_ratio),\n",
    "        unique_ratio=float(unique_ratio),\n",
    "        digits=int(digits),\n",
    "        words=len(words),\n",
    "    )\n",
    "\n",
    "\n",
    "def vectorize(f: ReviewFeatures) -> List[float]:\n",
    "    return [f.length, f.exclam, f.caps_ratio, f.unique_ratio, f.digits, f.words]\n",
    "\n",
    "\n",
    "# -------------------------------- Main workflow -------------------------------\n",
    "def pick_product(df: pd.DataFrame, cols: Dict[str, str | None],\n",
    "                 query: Optional[str], fallback_index: int = 0) -> Tuple[int, Dict]:\n",
    "    title_col = cols[\"title\"]\n",
    "    if query:\n",
    "        m = df[ df[title_col].astype(str).str.contains(query, case=False, na=False) ]\n",
    "        if not m.empty:\n",
    "            idx = int(m.index[0])\n",
    "            row = m.iloc[0].to_dict()\n",
    "            return idx, row\n",
    "    # fallback: nth row overall\n",
    "    row = df.iloc[fallback_index].to_dict()\n",
    "    return int(df.index[fallback_index]), row\n",
    "\n",
    "\n",
    "def main():\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    random.seed(RANDOM_SEED)\n",
    "\n",
    "    out_dir = Path(ARTIFACT_DIR)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Load data and map columns\n",
    "    df = load_csv(DATA_CSV)\n",
    "    cols = map_columns(df)\n",
    "\n",
    "    # 2) Choose product\n",
    "    idx, row = pick_product(df, cols, PRODUCT_QUERY, PRODUCT_INDEX)\n",
    "    title = str(row.get(cols[\"title\"]))\n",
    "    desc = str(row.get(cols[\"description\"])) if cols[\"description\"] else \"\"\n",
    "    retail = row.get(cols[\"retail_price\"])\n",
    "    disc = row.get(cols[\"discounted_price\"])\n",
    "    base = None\n",
    "    try:\n",
    "        base = float(disc) if disc == disc else None  # NaN check\n",
    "    except Exception:\n",
    "        base = None\n",
    "    if base is None:\n",
    "        try:\n",
    "            base = float(retail) if retail == retail else None\n",
    "        except Exception:\n",
    "            base = None\n",
    "    if base is None:\n",
    "        base = 100.0\n",
    "\n",
    "    print(f\"[INFO] Selected product @index {idx}: {title[:90]}{'...' if len(title)>90 else ''}\")\n",
    "    print(f\"[INFO] Base price used: {base:.2f}\")\n",
    "\n",
    "    # 3) Build synthetic last SEED_DAYS price history (same logic as training)\n",
    "    history = synthetic_series(base_price=base, days=SEED_DAYS,\n",
    "                               noise_frac=0.08, deal_prob=0.07, deal_frac=0.12)\n",
    "    dates_hist = [date.today() - timedelta(days=(SEED_DAYS - 1 - i)) for i in range(SEED_DAYS)]\n",
    "\n",
    "    # 4) Load LSTM model (if available) + forecast\n",
    "    model = load_lstm_model(H5_MODEL)\n",
    "    preds = forecast_next_k(history, FORECAST_DAYS, SEQ_LEN, model=model)\n",
    "    future_dates = [dates_hist[-1] + timedelta(days=i) for i in range(1, FORECAST_DAYS + 1)]\n",
    "\n",
    "    # 5) Save forecast CSV\n",
    "    df_forecast = pd.DataFrame({\n",
    "        \"date\": future_dates,\n",
    "        \"pred_price\": preds\n",
    "    })\n",
    "    forecast_csv = out_dir / \"price_forecast.csv\"\n",
    "    df_forecast.to_csv(forecast_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"[OK] Forecast CSV -> {forecast_csv}\")\n",
    "\n",
    "    # 6) Plot: history + forecast\n",
    "    fig, ax = plt.subplots(figsize=(8, 4.5), dpi=140)\n",
    "    ax.plot(dates_hist, history, marker=\"o\", linewidth=1, label=\"History\")\n",
    "    ax.plot(future_dates, preds, marker=\"o\", linewidth=1, label=f\"Forecast {FORECAST_DAYS}d\")\n",
    "    ax.set_title(f\"Price History & Forecast\\n{title[:70]}{'...' if len(title)>70 else ''}\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Price (₹)\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    out_png = out_dir / \"price_forecast.png\"\n",
    "    fig.savefig(out_png, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"[OK] Forecast plot -> {out_png}\")\n",
    "\n",
    "    # 7) Fake review scoring for the selected product\n",
    "    # Build pseudo \"reviews\" from description/title slices (same as training sensibly)\n",
    "    text_src = (desc if (desc and isinstance(desc, str)) else title) or \"\"\n",
    "    chunks = [text_src[:140], text_src[140:280], text_src[280:420]]\n",
    "    reviews = [c.strip() for c in chunks if c and len(c.strip()) > 10]\n",
    "\n",
    "    if FAKE_REVIEW_PKL.exists() and reviews:\n",
    "        with open(FAKE_REVIEW_PKL, \"rb\") as f:\n",
    "            clf = pickle.load(f)\n",
    "        X = np.array([vectorize(featurize(t)) for t in reviews], dtype=float)\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            probs = clf.predict_proba(X)[:, 1]\n",
    "        else:\n",
    "            if hasattr(clf, \"decision_function\"):\n",
    "                z = clf.decision_function(X)\n",
    "                probs = 1.0 / (1.0 + np.exp(-z))\n",
    "            else:\n",
    "                probs = clf.predict(X).astype(float)\n",
    "\n",
    "        df_scores = pd.DataFrame({\n",
    "            \"review_snippet\": reviews,\n",
    "            \"suspicious_proba\": probs\n",
    "        }).sort_values(\"suspicious_proba\", ascending=False)\n",
    "        out_scores = out_dir / \"fake_review_scores.csv\"\n",
    "        df_scores.to_csv(out_scores, index=False, encoding=\"utf-8\")\n",
    "        print(f\"[OK] Fake-review scores -> {out_scores}\")\n",
    "    else:\n",
    "        print(\"[WARN] No reviews extracted OR model file missing; skipping fake-review scoring.\")\n",
    "\n",
    "    # 8) Optional: naive sentiment pie for the same reviews (quick visual)\n",
    "    if reviews:\n",
    "        labels = [simple_sentiment_label(t) for t in reviews]\n",
    "        lab, counts = np.unique(labels, return_counts=True)\n",
    "        fig2, ax2 = plt.subplots(figsize=(5, 4), dpi=140)\n",
    "        ax2.pie(counts, labels=lab, autopct=\"%1.0f%%\")\n",
    "        ax2.set_title(\"Simple Sentiment (rule-based)\")\n",
    "        fig2.tight_layout()\n",
    "        pie_png = out_dir / \"sentiment_pie.png\"\n",
    "        fig2.savefig(pie_png, bbox_inches=\"tight\")\n",
    "        plt.close(fig2)\n",
    "        print(f\"[OK] Sentiment pie -> {pie_png}\")\n",
    "\n",
    "    # 9) Print a tiny summary\n",
    "    summary = {\n",
    "        \"product_index\": idx,\n",
    "        \"product_title\": title,\n",
    "        \"history_points\": len(history),\n",
    "        \"forecast_days\": FORECAST_DAYS,\n",
    "        \"price_forecast_png\": str(out_png),\n",
    "        \"price_forecast_csv\": str(forecast_csv),\n",
    "    }\n",
    "    print(\"\\n=== Prediction Summary ===\")\n",
    "    print(json.dumps(summary, indent=2, ensure_ascii=False))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb5833-3ad9-4f31-a2c3-9661ac9f38ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
